{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Images as signals\n",
    "\n",
    "In general for the exercises:\n",
    "\n",
    "- *Italics indicate text to explain the motivation or process behind a task*\n",
    "\n",
    "- **Bold text indicates a task**\n",
    "\n",
    "- Finally, \\* (one star) and ** (two stars) indicates a difficult or a particuarly difficult task, respectively. These are especially optional!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image representation\n",
    "\n",
    "\n",
    "As mentioned, images come in many different flavors ranging from pictures of artwork to LIDAR topography maps. In general, an image can be represented as a $C \\times N \\times M$ matrix of pixel intensities:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1M} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2M} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{N1} & a_{N2} & \\cdots & a_{NM}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Here, the $P$ dimension is left out (since it is a hassle to write mathematically in Markdown), but imagine $P$ of these matrices \"stacked\" on top of one another:\n",
    "\n",
    "Each of these matrices represents a \"channel\" in the image. Typically, in color images, there are 3 channels with each channel representing Red, Blue, and Green values respectively. Black and white images obviously only have one channel. Images with transparency have an extra \"alpha channel\" which holds binary values indicating whether or not that particular pixel is transparent. \n",
    "\n",
    "Later, particuarly with CNN's, we will see that individual image channels can hold different information about an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:37:57.374973Z",
     "start_time": "2024-08-27T11:37:55.769751Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images and such\n",
    "\n",
    "For this course, we will use Pillow for loading and handling of images. Some courses on DTU (for example computer vision) use CV2, but due to the (purely empirical) prevalence of Pillow used in Machine Learning applications, we will use it whenever necessary.\n",
    "\n",
    "Whenever it is *not* necessary to load images as... images, we will treat them purely as either numpy arrays or torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:37:57.517414Z",
     "start_time": "2024-08-27T11:37:57.377292Z"
    }
   },
   "outputs": [],
   "source": [
    "apple_image_path = os.path.join('images', 'image_gray.jpg')\n",
    "image_gray = np.array(Image.open(apple_image_path).convert('L'))\n",
    "plt.imshow(image_gray, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(\"Image shape (height, width):\", image_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "*As mentioned in the slides, we can also consider binary images where pixels are either \"off\" or \"on\". We determine whether a pixel is off or on based on the whether its original pixel value is smaller or larger than a given threshold*\n",
    "\n",
    "**1. Complete the function below to create a binarized image of the above image given a specific threshold**\n",
    "\n",
    "**2. Complete the second function below to grayscale a given RGB image**\n",
    "\n",
    "**3. Is is possible to binarize RGB images? How could this work? Discuss**\n",
    "\n",
    "*Test your implementations by using the code two cells below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:37:57.532537Z",
     "start_time": "2024-08-27T11:37:57.518500Z"
    }
   },
   "outputs": [],
   "source": [
    "def binarize_with_thresholding(image, threshold, binary_values=[255, 0]):\n",
    "    \"\"\"\n",
    "    Binarize an image based on a given threshold.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): np array representing a grayscaled image\n",
    "        threshold (int): Value so that if a pixel is above this, it will be considered 'on' otherwise it will be 'off' \n",
    "        binary_values (list, optional): List where the first element is the actual value 'on' pixels will be set to, second is value for the 'off' elements [255, 0].\n",
    "\n",
    "    Returns:\n",
    "        binarized_image (np.ndarray): np array representing the image, now binarized \n",
    "    \"\"\"\n",
    "\n",
    "    binarized_image = ...\n",
    "    \n",
    "    return binarized_image\n",
    "\n",
    "def rgb_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Grayscale an RGB image\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): np array representing the RGB image, must be of shape (n, m, c) \n",
    "\n",
    "    Returns:\n",
    "        imag_grayscaled (np.ndarray): np array representing the now grayscaled image, should be of shape (n, m)\n",
    "    \"\"\"\n",
    "    \n",
    "    image_grayscaled = ...\n",
    "\n",
    "    return image_grayscaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:00.957366Z",
     "start_time": "2024-08-27T11:37:57.534483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plotting a few images using the function\n",
    "\n",
    "original_image_path = os.path.join('images', 'img_1.jpg')\n",
    "\n",
    "# Load as normal using PIL, this will get the RGB image\n",
    "original_image = Image.open(original_image_path)\n",
    "\n",
    "# Load and use PIL.Image.convert('L') to convert to grayscale\n",
    "original_image_PIL_grayed = original_image.convert('L')\n",
    "\n",
    "# Unlike say CV2 objects, PIL objects cannot be treated as numpy arrays. We convert them to numpy for easier plotting and handling\n",
    "original_image = np.array(original_image)\n",
    "original_image_PIL_grayed = np.array(original_image_PIL_grayed)\n",
    "\n",
    "# Create a figure and axis for each image\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(original_image, vmin=0, vmax=255)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(original_image_PIL_grayed, cmap='gray', vmin=0, vmax=255) # cmap='gray' is used to display the image in grayscale\n",
    "axs[1].set_title('PIL grayed image')\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Get the manually binarized image\n",
    "binarized_image = binarize_with_thresholding(original_image_PIL_grayed, threshold=int(255/2))\n",
    "\n",
    "axs[2].imshow(binarized_image, cmap='gray', vmin=0, vmax=255) # Same as above, cmap gray\n",
    "axs[2].set_title('Binarized grayed image')\n",
    "axs[2].axis('off')\n",
    "\n",
    "# Get the manually grayed image\n",
    "image_manually_grayed = rgb_to_grayscale(original_image)\n",
    "\n",
    "axs[3].imshow(image_manually_grayed, cmap='gray', vmin=0, vmax=255) # Same as above, cmap gray\n",
    "axs[3].set_title('Manually grayed image')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Original image shape (height, width, channels):\", original_image.shape)\n",
    "print(\"PIL grayed image shape (height, width):\", original_image_PIL_grayed.shape)\n",
    "print(\"Manually grayed image shape (height, width):\", image_manually_grayed.shape)\n",
    "print(\"Binarized image shape (height, width):\", image_manually_grayed.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "*As mentioned in the lecture, a $28 \\times 28$ binary image has $2^{784}$ different possible images*\n",
    "\n",
    "**1. How many possible images do we have if we choose a non-binary $28 \\times 28$ image, using 8-bit values to represent pixel intensities?**\n",
    "\n",
    "\n",
    "**2. How many if we choose to use a continuous scale, simply the real numbers for representing pixel intensities instead?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "When faced with images that are too bright or too dark or have too high or low contrast, we can use histogram equalisation in order to scale the image. In this exercise you will implement a function that does exactly that. We will first artificially create images with pixels within a narrow range and some with increased contrast using the following functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:00.973155Z",
     "start_time": "2024-08-27T11:38:00.959558Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def squash_image(image, target_range=(0, 255)):\n",
    "    \"\"\"\n",
    "      Normalize the pixel values of an image to a specific range.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): np array representing the image\n",
    "        target_range (tuple, optional): Tuple representing the target range (min, max). Defaults to (0, 255).\n",
    "\n",
    "    Returns:\n",
    "        normalized_image np.ndarray: np array with pixel values normalized to the target range\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the min and max values of the original image\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    # Calculate the scale and shift to squash the values\n",
    "    scale = (target_range[1] - target_range[0]) / (max_val - min_val)\n",
    "    shift = target_range[0] - min_val * scale\n",
    "    \n",
    "    # Apply the scaling and shifting\n",
    "    normalized_image = image * scale + shift\n",
    "    \n",
    "    # Clip values to ensure they are within the target range\n",
    "    normalized_image = np.clip(normalized_image, target_range[0], target_range[1])\n",
    "    \n",
    "    # Convert to the appropriate data type (e.g., uint8 for images with range [0, 255])\n",
    "    normalized_image = normalized_image.astype(np.uint8)\n",
    "    \n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "def set_contrast(image, contrast_factor):\n",
    "    \"\"\"\n",
    "        Adjust the contrast of an image.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): np array representing the image\n",
    "        contrast_factor (float): Float value where 1.0 means no change, less than 1.0 decreases contrast\n",
    "          and greater than 1.0 increases contrast\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        contrast_image: np array with adjusted contrast\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the mean pixel value\n",
    "    mean = np.mean(image)\n",
    "    \n",
    "    # Adjust contrast\n",
    "    contrast_image = (image - mean) * contrast_factor + mean\n",
    "    \n",
    "    # Clip values to ensure they are within the valid range\n",
    "    contrast_image = np.clip(contrast_image, 0, 255)\n",
    "    \n",
    "    # Convert to the appropriate data type (e.g., uint8 for images with range [0, 255])\n",
    "    contrast_image = contrast_image.astype(np.uint8)\n",
    "    \n",
    "    return contrast_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:00.988526Z",
     "start_time": "2024-08-27T11:38:00.975260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now apply the functions:\n",
    "image_gray = np.array(Image.open(apple_image_path).convert('L'))\n",
    "dark_image = squash_image(image_gray, target_range=(0, 50))\n",
    "bright_image = squash_image(image_gray, target_range=(200, 255))\n",
    "low_contrast_image = set_contrast(image_gray, contrast_factor=0.5)\n",
    "high_constrast_image = set_contrast(image_gray, contrast_factor=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1. Using the following mathematical description of histogram equalisation, implement a function that does histogram equalisation on a grayscale image. Use numpy for the histogram and cdf calculations.**\n",
    "\n",
    "Let $ I(x, y) $ represent the intensity of the pixel at position $ (x, y) $ in the original image.\n",
    "The intensity values range from $ 0 $ to $ L-1 $, where $ L $ is the number of possible intensity levels (e.g., $ L = 256 $ for an 8-bit grayscale image).\n",
    "The probability density function (PDF) of the intensity values is denoted as $ p_I(i) $, where $ i $ is an intensity value and $ p_I(i) $ is the probability that a randomly selected pixel has intensity $ i $.\n",
    "The cumulative distribution function (CDF) of the intensity values is denoted as $ c_I(i) $.\n",
    "\n",
    " **Steps for Histogram Equalization**\n",
    "\n",
    "1. **Calculate the PDF:**\n",
    "   $$\n",
    "   p_I(i) = \\frac{\\text{number of pixels with intensity } i}{\\text{total number of pixels}}\n",
    "   $$\n",
    "\n",
    "2. **Calculate the CDF:**\n",
    "   $$\n",
    "   c_I(i) = \\sum_{j=0}^{i} p_I(j)\n",
    "   $$\n",
    "   The CDF $ c_I(i) $ represents the cumulative sum of the PDF up to intensity $ i $.\n",
    "\n",
    "3. **Transformation Function:**\n",
    "   The new intensity value $ I_{\\text{eq}}(x, y) $ for each pixel is obtained using the transformation function:\n",
    "   $$\n",
    "   I_{\\text{eq}}(x, y) = (L-1) \\cdot c_I(I(x, y))\n",
    "   $$\n",
    "   This equation maps the original intensity values to new values based on the CDF, effectively spreading the intensity values over the entire range.\n",
    "\n",
    "\n",
    "**2. If an image has $X$ unique pixel values before histogram equalisation, how many will it have after?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:50:10.357068Z",
     "start_time": "2024-08-27T11:50:10.350944Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def histogram_equalisation(image):\n",
    "    \"\"\"\n",
    "    Perform histogram equalization on a grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): Input grayscale image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Histogram-equalized image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate the histogram of the image\n",
    "    hist, bins = ...\n",
    "    \n",
    "    # Step 2: Calculate the cumulative distribution function (CDF)\n",
    "    cdf = ...\n",
    "    \n",
    "    # Normalize the CDF to lie between 0 and 255\n",
    "    cdf_normalized = ...\n",
    "    \n",
    "    # Step 3: Use the CDF to map the original intensities to the equalized values\n",
    "    image_equalized = ...\n",
    "    \n",
    "    return image_equalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:50:11.231081Z",
     "start_time": "2024-08-27T11:50:11.222426Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we use the following plotting function to display the results for each of our 4 images:\n",
    "def display_image_hist_and_cdf(image_gray, name=''):\n",
    "    \n",
    "    # Create a figure with three subplots\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Display the equalized image\n",
    "    ax[0].imshow(image_gray, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0].set_title(f'Histogram Equalized Image {name}')\n",
    "    ax[0].axis('off')  # Hide axes\n",
    "    \n",
    "    # Plot the histogram\n",
    "    hist, bins = np.histogram(image_gray.flatten(), 256, [0, 256])\n",
    "    ax[1].bar(range(256), hist, color='gray', width=1)\n",
    "    ax[1].set_title('Histogram')\n",
    "    ax[1].set_xlim([0, 255])\n",
    "    ax[1].set_xlabel('Pixel Intensity')\n",
    "    ax[1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot the CDF\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf / cdf.max()\n",
    "    ax[2].plot(cdf_normalized, color='blue')\n",
    "    ax[2].set_title('Cumulative Distribution Function (CDF)')\n",
    "    ax[2].set_xlim([0, 255])\n",
    "    # ax[2].set_ylim([0, 1])\n",
    "    ax[2].set_xlabel('Pixel Intensity')\n",
    "    ax[2].set_ylabel('Cumulative Probability')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:50:15.925683Z",
     "start_time": "2024-08-27T11:50:12.488469Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img, name in zip((dark_image, bright_image, low_contrast_image, high_constrast_image),( 'Dark', 'Bright', 'Low contrast', 'High contrast')):\n",
    "    display_image_hist_and_cdf(img, name = name+' before processing')\n",
    "    img_equalised = histogram_equalisation(img)\n",
    "    display_image_hist_and_cdf(img_equalised, name=name+' after processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color Channels\n",
    "\n",
    "*Typically placed as either the -1st (last) or the 0th (first) dimension of an image, the channels in an RGB image obviously hold Red-Blue-Green values. For all intents and purposes, these can just be seen as dimensions of a matrix, and subject to regular matrix operations*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "*One should be cognisant of ones images being interpreted in the correct way by whatever package being used. PIL uses RGB by default, while CV2 uses BGR, for example.*\n",
    "\n",
    "**1. Swap the channels of the above image to make it BGR instead of RGB (should swap blue for red and vice versa)**\n",
    "\n",
    "*Test your implementation by showing the image two cells below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:01.298505Z",
     "start_time": "2024-08-27T11:38:01.005612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load image and convert to numpy array, as normal\n",
    "image_path = os.path.join('images', 'img_1.jpg')\n",
    "rgb_image_path = os.path.join('images', 'img_1.jpg')\n",
    "rgb_image = np.array(Image.open(rgb_image_path))\n",
    "\n",
    "# Swap channels here\n",
    "bgr_image = ...\n",
    "\n",
    "print(\"RGB image shape (height, width, channels):\", np.array(rgb_image).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:02.429853Z",
     "start_time": "2024-08-27T11:38:01.299740Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "axs[0].imshow(rgb_image, vmin=0, vmax=255)\n",
    "axs[0].set_title('RGB Image')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(bgr_image, vmin=0, vmax=255)\n",
    "axs[1].set_title('BGR Image')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "*Looking at the relative frequency of different colors in an image can be useful way to collect summary statistics on the image in general*\n",
    "\n",
    "**1. Examine the color histograms of the different images in the week1/images folder, or ones you find yourself, do they make sense? What do they tell you about the image itself?**\n",
    "\n",
    "\n",
    "\n",
    "**2. Try modifying some of the colors by fixed amounts, either by multiplying with, or adding scalar values, how do the histograms change... What should you be congnisant of in these cases?**\n",
    "\n",
    "\n",
    "**3. Normalize each histogram by total number of values of that color to get a \"CDF\" of pixel values**\n",
    "\n",
    "**4. What is the potential value of normalizing by number of pixels vs not normalizing?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:04.245819Z",
     "start_time": "2024-08-27T11:38:02.431190Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_color_distribution(image, density=False):\n",
    "    \"\"\"\n",
    "    Display the distribution of pixels in each color channel (RGB) of an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: NumPy array representing the image.\n",
    "    \"\"\"\n",
    "    # Split the image into its color channels\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(18, 6))\n",
    "\n",
    "    # Show the original image\n",
    "    axs[0].set_title('Image')\n",
    "    axs[0].imshow(image, vmin=0, vmax=255)\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot the histogram of each of the color channels\n",
    "    colors = ('b', 'g', 'r')\n",
    "    channel_names = ('Blue', 'Green', 'Red')\n",
    "    for i, (color, channel_name) in enumerate(zip(colors, channel_names)):\n",
    "        axs[i + 1].hist(image[..., i].flatten(), bins=256, color=color, alpha=0.7, density=density)\n",
    "        axs[i + 1].set_title(f'{channel_name} Channel')\n",
    "        axs[i + 1].set_xlabel('Pixel Intensity')\n",
    "        axs[i + 1].set_ylabel('Frequency')\n",
    "        axs[i + 1].set_xlim([0, 256])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_color_distribution(rgb_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distance Metrics and simliarity measures\n",
    "\n",
    "*Distance metrics (often \"Incorrectly\" called 'norms') can be considered as a ways of measuring simliarity between two datums. You should already have learned about (and used) the concept in 02450, but given their importance, they are recapped here (somewhat informally).*\n",
    "\n",
    "\n",
    "*A distance metric is a pair of a **set $\\mathcal{M}$** and a **function $d$** such that: $d: \\mathcal{M} \\times \\mathcal{M} \\rightarrow \\mathbb{R}$*\n",
    "\n",
    "*I.E a function that takes two elements from a set and spits out a real number that compares them*\n",
    "\n",
    "*Apart from this, it must also satisfy the following conditions (also mentioned in slide w1 slide 39)*\n",
    "\n",
    "- *Non-negativity*: $d(x,y) \\geq 0 \\quad \\forall x \\forall y$\n",
    "  - *A distance can never be negative*\n",
    "- *Indiscernibility of identities*: $d(x, y) = 0 \\iff x  = y$\n",
    "  -  *A distance is zero only if we compare an element with a copy of itself*\n",
    "-  *Symmetry*: $d(x,y) = d(y,x) \\quad \\forall x \\forall y$\n",
    "   -  *A distance from a to b is the same as from b to a*\n",
    "-  *Triangle inequality:* $d(x,z) \\leq d(x, y) + d(y,z) \\quad \\forall x \\forall y \\forall z$\n",
    "   -  *The distance from a to c is always the same as or shorter than from a to b to c*\n",
    "\n",
    "\n",
    "*In this course, we work with the following norms:*\n",
    "\n",
    "- *Minkowski (p-norm)*:\n",
    "  - $d_p(x,y) = \\left(\\sum^n_{i=1} |x_i - y_i|^p \\right)^{\\frac{1}{p}} \\quad \\forall p | p \\geq 1$\n",
    "\n",
    "*And thats it... Manhattan (absolute)  and Euclidian are also included in this. Do note, that the Minkowski is only a true distance metric (and norm) for $p \\geq 1$*\n",
    "\n",
    "\n",
    "*As for similarity measures (for which the above requirements do not apply), we also use:*\n",
    "\n",
    "- *Cosine similarity (a sort of angle between vectors)*\n",
    "  - $d_{cos}(x,y) = \\frac{\\mathbf{x} \\cdot \\mathbf{y} } {||\\mathbf{x}|| \\space ||\\mathbf{y}||}$\n",
    "  - $ = \\frac{\\sum^n_{i=1} x_i y_i}{\\sqrt{\\sum^n_{i=1}x_i^2} \\sqrt{\\sum^n_{i=1} y^2_i}}$ \n",
    "    - $1$: Vectors point to same direction \n",
    "    - $0$: Vectors are orthogonal (90 degree angle to one another)\n",
    "    - $-1$: Vectors point in opposite directions\n",
    "- *Squared (euclidian) distance (not a distance metric)*\n",
    "  - $d_{SE}(x,y) = \\left(\\sum^n_{i=1} (x_i - y_i)^2 \\right)$\n",
    "  - Often used for loss calculation (you may have seen that already)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Write code for euclidian, manhattan and cosine distance measures\n",
    "- Show that the cosine similarity and the p-norm are norms (have certain properties of norms)\n",
    "- Perhaps something with using the different norms on the images that have been slightly perturbed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "\n",
    "*As mentioned, the squared distance somewhat unintuitively is not a true distance metric, same goes for the cosine distance*\n",
    "\n",
    "\n",
    "**1. First, argue why the squared distance is *not* a distance metric (Hint: It does not satisfy the triangle inequality)**\n",
    "\n",
    "\n",
    "**2. Next, argue for why the cosine distance is not a true distance metric**\n",
    "\n",
    "\n",
    "<!-- **2. Now, argue mathematically for why the Euclidian distance is indeed a distance metric (I.E fulfills the above requirements for a distance metric)** -->\n",
    "\n",
    "**3. As mentioned above, the Minkowski distance is only a true distance measure for $p \\geq 1$, why is this?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "\n",
    "**1. Implement the Euclidian, manhattan, cosine, and minkowski distances below respectively, you may be tempted to use built-in numpy functions, do not**\n",
    "\n",
    "**2. Verify your implementations with the plot_distance_heatmap function two cells below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:04.261408Z",
     "start_time": "2024-08-27T11:38:04.246820Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vec1, vec2, *args):\n",
    "    dist_l2 = ...\n",
    "    return dist_l2\n",
    "\n",
    "def manhattan_distance(vec1, vec2, *args):\n",
    "    dist_l1 = ...\n",
    "    return dist_l1\n",
    "\n",
    "def cosine_distance(vec1, vec2, *args):\n",
    "    \"Please remember this is the cosine *distance*\"\n",
    "\n",
    "    dist_cos = ...\n",
    "\n",
    "    return dist_cos\n",
    "\n",
    "def minkowski_distance(vec1, vec2, p):\n",
    "\n",
    "    dist_minkowski = ...\n",
    "\n",
    "    return dist_minkowski\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:04.276812Z",
     "start_time": "2024-08-27T11:38:04.263613Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_distance_heatmap(distance_metrics, x_range=(-20, 20), y_range=(-20, 20), resolution=200, names='', **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the given distance metric for 2D vectors over a specified range.\n",
    "\n",
    "    Parameters:\n",
    "    - distance_metric: A function that takes two 2D vectors and returns a scalar distance.\n",
    "    - x_range: A tuple specifying the range of x values (min, max).\n",
    "    - y_range: A tuple specifying the range of y values (min, max).\n",
    "    - resolution: The number of points along each axis.\n",
    "    \"\"\"\n",
    "    # Generate a grid of points\n",
    "    x = np.linspace(x_range[0], x_range[1], resolution)\n",
    "    y = np.linspace(y_range[0], y_range[1], resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    ps = kwargs.get('ps', [None for el in distance_metrics])\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=ceil(len(distance_metrics) / 2), ncols=2, figsize=(8, 6))\n",
    "    \n",
    "    for idx, (name, metric, ax) in enumerate(zip(names, distance_metrics, axs.flatten())):\n",
    "        # Compute the distance metric for each point in the grid\n",
    "        Z = np.zeros_like(X)\n",
    "        for i in range(resolution):\n",
    "            for j in range(resolution):\n",
    "                vector = np.array([X[i, j], Y[i, j]])\n",
    "                Z[i, j] = metric(vector, np.array([1e-5, 1e-5]), ps[idx])\n",
    "        # Plot the heatmap\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.grid(\"both\")\n",
    "        ax.set_title(f'{name}')\n",
    "        cont = ax.contourf(X, Y, Z, cmap='viridis')\n",
    "        fig.colorbar(cont, label='Distance', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:04.955617Z",
     "start_time": "2024-08-27T11:38:04.278935Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distance_heatmap((euclidean_distance, manhattan_distance, cosine_distance), names=(\"Euclidean\", \"Manhattan\", \"Cosine\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:05.862121Z",
     "start_time": "2024-08-27T11:38:04.956714Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distance_heatmap((manhattan_distance, minkowski_distance, euclidean_distance, minkowski_distance), names=(\"Manhattan\", \"L1 norm\", \"Euclidean\", 'L2 norm'), ps=[1, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:38:08.027086Z",
     "start_time": "2024-08-27T11:38:06.987874Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = [1, 0.9, 0.75, 0.5]\n",
    "plot_distance_heatmap([minkowski_distance for _ in ps], names=[f'Minowski p={val}' for val in ps], ps=ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "\n",
    "**1. Find uses cases where it is most beneficial to use the Manhattan, Euclidian, and Cosine distance measure respectively**\n",
    "\n",
    "\n",
    "****2. What happens with the minkowski distance as $p \\rightarrow \\infty$? If we use this to compare two distances with one another, what does it measure?**\n",
    "\n",
    "\n",
    "****3. What happens withe the minkowski distance as $p \\rightarrow 0$? If we use this to compare two distances with one another, what does it measure? (Assume this is real analysis, and that $0^0 = 0$**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A final note on these distances\n",
    "\n",
    "While it is generally true that the distance measures above are fundamental in machine learning, they are not exactly useful per say, for what we are working with now images. Simply using the euclidian distance, for example on a vectorized image, could give a ***huge*** distance if just one pixel is different.\n",
    "\n",
    "Moreover, and perhaps more importantly, the distances above do not use any sort of spatial information. That is, where the different indices (pixels in an image) in one or the other vector, are in relation to one another, has no effect on the distance itself. To actually measure differences in images therefore, is a harder problem, one that we will in part learn to tackle next time when we use **Convolution**. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
